{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e5ea1b",
   "metadata": {},
   "source": [
    "数据处理，就是将收集到的数据进行加工、整理，再进行分析。\n",
    "\n",
    "数据处理是数据分析前必不可少的工作，并且在整个数据分析工作量中占据了大部分比例。\n",
    "\n",
    "今天，我们将学习数据处理中的一个重要步骤：数据的导入。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3039ce4",
   "metadata": {},
   "source": [
    "pandas的DataFrame有大量数据处理的方法，所以pandas会将数据读取为DataFrame对象，以便进行后续的数据处理操作。\n",
    "\n",
    "在大多数情况下，处理数据和分析数据时，我们的数据来源都是CSV文件和Excel文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a616cfea",
   "metadata": {},
   "source": [
    "# 今日目标\n",
    "\n",
    "接下来，我们将先了解一个关于文件的基本概念：路径。\n",
    "\n",
    "然后，我们将学习如何使用pandas模块读取CSV文件和读取Excel文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af0b913",
   "metadata": {},
   "source": [
    "# 文件路径"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeae1679",
   "metadata": {},
   "source": [
    "路径（Path）用来表示文件或文件夹的位置。\n",
    "\n",
    "当我们需要访问文件或文件夹时，路径就像现实中的地址一样，帮助我们找到目标文件或文件夹在什么位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb64eb70",
   "metadata": {},
   "source": [
    "不同的操作系统，文件路径的写法不同。\n",
    "\n",
    "例如，Windows系统中的文件路径是 \"C:\\Users\\胖虎\\photo.jpg\"。\n",
    "\n",
    "我们使用反斜线 ( \\ ) 分隔各个文件夹和文件名。\n",
    "\n",
    "同时，在路径的最前面，是盘符的字母和一个英文冒号，表示文件或文件夹具体是在哪个盘的路径下。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d204b6",
   "metadata": {},
   "source": [
    "而在macOS系统中的文件路径是 \"/Users/胖虎/photo.jpg\"（如图所示）。\n",
    "\n",
    "文件夹和文件名使用正斜线 ( / ) 进行分隔。\n",
    "\n",
    "需要注意的是，macOS系统中，没有盘符的概念，所有的路径都是从根目录（ / ） 开始。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986654e1",
   "metadata": {},
   "source": [
    "了解文件的基本概念后，我们就可以开始学习在pandas模块中读取CSV文件和Excel文件啦。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a194480",
   "metadata": {},
   "source": [
    "# 读取CSV文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159d03a5",
   "metadata": {},
   "source": [
    "## 什么是CSV文件呢？\n",
    "\n",
    "CSV（Comma-Separated Values）（逗号分隔值）文件以纯文本的形式储存数字、文本等表格数据。\n",
    "\n",
    "它的数据格式如图所示，文件中多个数据之间通常用逗号分隔，每一行的数据都是相同的结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe97ae1",
   "metadata": {},
   "source": [
    "## 读取CSV文件\n",
    "\n",
    "在pandas中，读取CSV文件主要使用pd.read_csv()函数。\n",
    "\n",
    "将 必选参数 - CSV文件的路径 传入该函数中，便可以得到对应的DataFrame格式的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c99e09",
   "metadata": {},
   "source": [
    "下面是一个简单的示例：将一份电商平台订单数据的路径传入pd.read_csv()函数后，得到了该数据对应的DataFrame格式的数据。\n",
    "\n",
    "此时，读取出的数据会被自动添加默认从0开始的行索引index和列索引columns，并且columns默认是原来数据的第一行。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f2850",
   "metadata": {},
   "source": [
    "这三行代码读取了一份CSV文件，并将生成的数据输出进行查看。      \n",
    "\n",
    "第一行导入了pandas模块，并使用\"pd\"作为该模块的简写。\n",
    "\n",
    "第二行将路径为 \"/Users/yequ/电商数据清洗.csv\" 的CSV文件作为参数传入到 pd.read_csv() 函数中，并将函数返回的结果赋值给了变量data。\n",
    "\n",
    "第三行输出该变量进行数据查看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0606c83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  order_id   user_id  payment  price  items_count  cutdown_price  \\\n",
      "0          1   3515712  34982388     6200   6200            4              0   \n",
      "1          2   3515713  17463833     7000   7000            3              0   \n",
      "2          3   3515714  70145358    10000  10000            5              0   \n",
      "3          4   3515715  46519215     8500   8500            4              0   \n",
      "4          5   3515716  37811404     5102   5102            8              0   \n",
      "...      ...       ...       ...      ...    ...          ...            ...   \n",
      "85647  86128   3601839  80511560     4601   5601            4           1000   \n",
      "85648  86129   3601840  71210814     6500   6500            3              0   \n",
      "85649  86130   3601841  71565319    18600  18600            5              0   \n",
      "85650  86131   3601842  55948700    10200  10200            3              0   \n",
      "85651  86132   3601843  14576333     5500   5500            2              0   \n",
      "\n",
      "       post_fee  pay_type      create_time         pay_time  \n",
      "0             0     202.0  2018/1/31 16:06  2018/1/31 16:06  \n",
      "1             0     202.0  2018/1/31 16:13  2018/1/31 16:14  \n",
      "2             0     202.0  2018/1/31 23:52  2018/1/31 23:52  \n",
      "3             0     202.0    2018/2/1 0:05    2018/2/1 0:05  \n",
      "4             0     202.0    2018/2/1 0:51    2018/2/1 0:51  \n",
      "...         ...       ...              ...              ...  \n",
      "85647         0     202.0  2018/7/20 15:02  2018/7/20 15:02  \n",
      "85648         0     202.0  2018/7/20 15:05  2018/7/20 15:05  \n",
      "85649         0     102.0  2018/7/20 15:33  2018/7/20 15:35  \n",
      "85650         0     202.0  2018/7/20 15:35  2018/7/20 15:35  \n",
      "85651         0     202.0  2018/7/20 15:43  2018/7/20 15:43  \n",
      "\n",
      "[85652 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"/Users/xiaojiangyue/programming-study-notes/Python/数据分析/lesson_4_output/yequ/电商数据清洗.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93efd147",
   "metadata": {},
   "source": [
    "作为参数传入pd.read_csv()函数中，该函数将返回一个对应的DataFrame。\n",
    "\n",
    "使用Windows系统的同学在自己的电脑上运行代码时，需要注意路径前要加一个r表示字符串不需要转义。\n",
    "\n",
    "如：pd.read_csv(r\"D:\\Users\\yequ\\电商数据清洗.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c53520",
   "metadata": {},
   "source": [
    "# 指定index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021d5b59",
   "metadata": {},
   "source": [
    "对于理想情况下的数据，只要像刚才一样，简单地指定CSV文件的路径，便可以得到DataFrame格式的数据。\n",
    "\n",
    "但大多时候，这样的方式并不能保证我们在所有情况下都能读取到想要的数据。\n",
    "\n",
    "所以，pd.read_csv()函数为我们提供了大量的可选参数来处理这些形形色色的情况。\n",
    "\n",
    "接下来，我们将通过分析3个最常见的情况来帮助大家更好地理解 pd.read_csv()函数中的可选参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f891e786",
   "metadata": {},
   "source": [
    "## 1. 需要更有意义的index\n",
    "\n",
    "之前的例子中，我们在调用pd.read_csv()函数时没有单独定义index，所以读取出的DataFrame的index默认从0开始。\n",
    "\n",
    "但往往在处理数据时需要更有意义的index，这会有利于我们对数据进行观察和分析。\n",
    "\n",
    "比如，将 \"order_id\"，也就是订单号这一列，作为DataFrame的索引。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d903b3",
   "metadata": {},
   "source": [
    "1. 指定index - index_col\n",
    "\n",
    "对于这种情况，pd.read_csv()函数提供了一个参数：index_col，将 列名作为字符串 传入该参数便可以指定index。\n",
    "\n",
    "在这里，我们指定 \"order_id\" 这一列作为index。具体代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bf59e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id   user_id  payment  price  items_count  cutdown_price  \\\n",
      "order_id                                                                \n",
      "3515712       1  34982388     6200   6200            4              0   \n",
      "3515713       2  17463833     7000   7000            3              0   \n",
      "3515714       3  70145358    10000  10000            5              0   \n",
      "3515715       4  46519215     8500   8500            4              0   \n",
      "3515716       5  37811404     5102   5102            8              0   \n",
      "...         ...       ...      ...    ...          ...            ...   \n",
      "3601839   86128  80511560     4601   5601            4           1000   \n",
      "3601840   86129  71210814     6500   6500            3              0   \n",
      "3601841   86130  71565319    18600  18600            5              0   \n",
      "3601842   86131  55948700    10200  10200            3              0   \n",
      "3601843   86132  14576333     5500   5500            2              0   \n",
      "\n",
      "          post_fee  pay_type      create_time         pay_time  \n",
      "order_id                                                        \n",
      "3515712          0     202.0  2018/1/31 16:06  2018/1/31 16:06  \n",
      "3515713          0     202.0  2018/1/31 16:13  2018/1/31 16:14  \n",
      "3515714          0     202.0  2018/1/31 23:52  2018/1/31 23:52  \n",
      "3515715          0     202.0    2018/2/1 0:05    2018/2/1 0:05  \n",
      "3515716          0     202.0    2018/2/1 0:51    2018/2/1 0:51  \n",
      "...            ...       ...              ...              ...  \n",
      "3601839          0     202.0  2018/7/20 15:02  2018/7/20 15:02  \n",
      "3601840          0     202.0  2018/7/20 15:05  2018/7/20 15:05  \n",
      "3601841          0     102.0  2018/7/20 15:33  2018/7/20 15:35  \n",
      "3601842          0     202.0  2018/7/20 15:35  2018/7/20 15:35  \n",
      "3601843          0     202.0  2018/7/20 15:43  2018/7/20 15:43  \n",
      "\n",
      "[85652 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# 导入pandas模块，并以\"pd\"为该模块的简写\n",
    "import pandas as pd\n",
    "\n",
    "# 使用pd.read_csv()函数读取路径为 \"/Users/yequ/电商数据清洗.csv\" 的CSV文件\n",
    "# 并通过参数index_col来指定\"order_id\"列为index\n",
    "# 将结果赋值给变量data\n",
    "data = pd.read_csv(\"/Users/xiaojiangyue/programming-study-notes/Python/数据分析/lesson_4_output/yequ/电商数据清洗.csv\", index_col=\"order_id\")\n",
    "\n",
    "# 使用print()输出变量data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d2ab75",
   "metadata": {},
   "source": [
    "## 2. 读取某几列数据\n",
    "\n",
    "现在，我们想要计算每个商品的平均客单价，具体的计算方式是：销售额/销量，也就是payment/items_count。\n",
    "\n",
    "因为我们只需要用到 \"payment\" 和 \"items_count\" 这两列数据，那么在这样的情况下，读取数据中所有列的方式显然效率不够高并且非常消耗内存。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ecbe4f",
   "metadata": {},
   "source": [
    "2. 读取指定列 - usecols\n",
    "\n",
    "针对只需要读取数据中的某一列或多列的情况，pd.read_csv()函数提供了一个参数：usecols，将包含对应的columns的列表传入该参数即可。\n",
    "\n",
    "比如，只读取 \"payment\" 和 \"items_count\" 这两列数据的具体代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "836b7a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       payment  items_count\n",
      "0         6200            4\n",
      "1         7000            3\n",
      "2        10000            5\n",
      "3         8500            4\n",
      "4         5102            8\n",
      "...        ...          ...\n",
      "85647     4601            4\n",
      "85648     6500            3\n",
      "85649    18600            5\n",
      "85650    10200            3\n",
      "85651     5500            2\n",
      "\n",
      "[85652 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 导入pandas模块，并以\"pd\"为该模块的简写\n",
    "import pandas as pd\n",
    "\n",
    "# TODO 使用pd.read_csv()函数和usecols参数\n",
    "# 读取路径为 \"/Users/yequ/电商数据清洗.csv\" 的CSV文件里：\n",
    "# \"payment\"和\"items_count\"这两列中的数据\n",
    "# 并将结果赋值给变量data\n",
    "data = pd.read_csv(\"/Users/xiaojiangyue/programming-study-notes/Python/数据分析/lesson_4_output/yequ/电商数据清洗.csv\", usecols = [\"payment\", \"items_count\"])\n",
    "\n",
    "# 使用print()输出变量data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b629d98",
   "metadata": {},
   "source": [
    "## 3. 给数据添加columns\n",
    "\n",
    "如果CSV文件没有列名，那么使用pd.read_csv()函数就是从第一行直接开始数据的录入了。\n",
    "\n",
    "这时，就需要给数据添加上columns，让数据变得完整。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a6bd3e",
   "metadata": {},
   "source": [
    "3. 添加columns - header=None和names\n",
    "\n",
    "针对刚才的情况，pd.read_csv()函数提供了两个参数，分别是：\n",
    "\n",
    "header=None，表明原数据中没有columns；          \n",
    "names，将包含columns的列表传入该参数即可给数据添加columns。\n",
    "\n",
    "比如，给没有columns的CSV文件添加 \"订单号\",\"用户id\",\"支付金额\",\"商品价格\",\"购买数量\",\"支付时间\" 作为columns的具体代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374efd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           订单号      用户id   支付金额   商品价格  购买数量             支付时间\n",
      "0      3515712  34982388   6200   6200     4  2018/1/31 16:06\n",
      "1      3515713  17463833   7000   7000     3  2018/1/31 16:14\n",
      "2      3515714  70145358  10000  10000     5  2018/1/31 23:52\n",
      "3      3515715  46519215   8500   8500     4    2018/2/1 0:05\n",
      "4      3515716  37811404   5102   5102     8    2018/2/1 0:51\n",
      "...        ...       ...    ...    ...   ...              ...\n",
      "85647  3601839  80511560   4601   5601     4  2018/7/20 15:02\n",
      "85648  3601840  71210814   6500   6500     3  2018/7/20 15:05\n",
      "85649  3601841  71565319  18600  18600     5  2018/7/20 15:35\n",
      "85650  3601842  55948700  10200  10200     3  2018/7/20 15:35\n",
      "85651  3601843  14576333   5500   5500     2  2018/7/20 15:43\n",
      "\n",
      "[85652 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# 导入pandas模块，并以\"pd\"为该模块的简写\n",
    "import pandas as pd\n",
    "\n",
    "# TODO 使用pd.read_csv()函数、header参数和names参数\n",
    "# 读取路径为 \"/Users/yequ/order_withoutColumns.csv\" 的CSV文件\n",
    "# 将数据的columns设置为:\"订单号\",\"用户id\",\"支付金额\",\"商品价格\",\"购买数量\",\"支付时间\"\n",
    "# 将结果赋值给变量data\n",
    "data = pd.read_csv(\"/Users/xiaojiangyue/programming-study-notes/Python/数据分析/lesson_4_output/yequ/order_withoutColumns.csv\", header = None, names = [\"订单号\",\"用户id\",\"支付金额\",\"商品价格\",\"购买数量\",\"支付时间\"])\n",
    "\n",
    "# 使用print()输出变量data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86f1c21",
   "metadata": {},
   "source": [
    "总结一下，刚刚遇到的3个场景中，我们分别使用了以下4个可选参数：\n",
    "\n",
    "1. 指定index - index_col\n",
    "2. 读取指定列 - usecols\n",
    "3. 添加columns - header=None和names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d20290",
   "metadata": {},
   "source": [
    "# xlrd模块的安装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f23294",
   "metadata": {},
   "source": [
    "现在，我们已经有了读取CSV文件的经验，那么Excel文件的读取也就轻车熟路了，因为Excel文件读取和CSV文件读取之间的区别就是一个词 - Excel。\n",
    "\n",
    "在学习读取Excel文件前，我们需要先安装一个用于读取Excel文件的辅助工具：xlrd 模块。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4402a85",
   "metadata": {},
   "source": [
    "xlrd 模块可读取.xls和.xlsx文件。\n",
    "\n",
    "安装 xlrd 模块非常简单，在终端输入代码，`pip install xlrd==1.2.0 `即可。\n",
    "\n",
    "该模块安装后不需要在代码中导入。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268d65a7",
   "metadata": {},
   "source": [
    "# 读取Excel文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9f605",
   "metadata": {},
   "source": [
    "## 什么是Excel文件呢？\n",
    "\n",
    "Excel文件是平常办公中最常见的一种表格文件。\n",
    "\n",
    "一个Excel文件中可以有很多个工作表（Worksheet）。\n",
    "\n",
    "示例中，2019年4月销售订单.xlsx 中，一共有四个工作表：销售商品、销售订单数据、芹菜味薯片、火龙果可乐。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc31cf38",
   "metadata": {},
   "source": [
    "## 读取Excel文件\n",
    "\n",
    "在pandas模块中，读取Excel文件主要使用pd.read_excel()函数。\n",
    "\n",
    "将 必选参数 - Excel文件的路径 传入该函数中，便可以得到对应的DataFrame格式的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1011ebb",
   "metadata": {},
   "source": [
    "下面是一个简单的示例：将一份2019年的超市销售订单数据的Excel文件路径传入pd.read_excel()函数后，得到了该数据对应的DataFrame格式的数据。\n",
    "\n",
    "此时，读取出的数据会被自动添加默认从0开始的行索引index和列索引columns，并且columns默认是原来数据的第一行。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b6344",
   "metadata": {},
   "source": [
    "和读取CSV文件一样，pd.read_excel()函数也为我们提供了大量的可选参数来处理形形色色的情况。\n",
    "\n",
    "之前学习的参数也可以用在pd.read_excel()函数中。\n",
    "\n",
    "除此之外，还有1个特殊的场景是只在处理Excel文件时能遇到的。\n",
    "\n",
    "接下来，我们将通过分析这个场景来帮助大家理解pd.read_excel()函数中另一个最常用的可选参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76836c02",
   "metadata": {},
   "source": [
    "## 1. 读取某一个工作表\n",
    "\n",
    "当Excel文件里有多个工作表时，默认情况下，pd.read_excel()函数会读取第一个工作表。\n",
    "\n",
    "现在，我们想要具体分析该超市的销售情况，那么就需要读取Excel文件中的第二个工作表 - \"销售订单数据\"。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561d24a7",
   "metadata": {},
   "source": [
    "1. 读取指定工作表 - sheet_name\n",
    "\n",
    "当我们需要读取指定工作表时，pd.read_excel()函数提供了一个参数：sheet_name，将要读取的工作表名称作为字符串传入该参数即可。\n",
    "\n",
    "比如，读取 \"销售订单数据\" 这个工作表的具体代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0f09a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                订单号    商品ID       商品名    品牌  类别     规格  单价  数量   总价  \\\n",
      "0    98232019040002  700009     芹菜味薯片  开口哭牌  零食   200克  20   2   40   \n",
      "1    98232019040003  700006  没有一点味口香糖  开口哭牌  零食   100克  15   2   30   \n",
      "2    98232019040004  700013     火龙果可乐  君再来牌  饮料  550毫升   5   5   25   \n",
      "3    98232019040005  700003    芹菜味口香糖  开口哭牌  零食   100克  15   1   15   \n",
      "4    98232019040006  700009     芹菜味薯片  开口哭牌  零食   200克  20   1   20   \n",
      "..              ...     ...       ...   ...  ..    ...  ..  ..  ...   \n",
      "300  98232019040302  700011     蟹黄味薯片  开口哭牌  零食   200克  20   5  100   \n",
      "301  98232019040303  700016     夏夜雨可乐  君再来牌  饮料  550毫升   5   1    5   \n",
      "302  98232019040304  700015     青草味可乐  君再来牌  饮料  550毫升   5   1    5   \n",
      "303  98232019040305  700015     青草味可乐  君再来牌  饮料  550毫升   5   1    5   \n",
      "304  98232019040306  700005    蟹黄味口香糖  开口哭牌  零食   100克  15   2   30   \n",
      "\n",
      "                   下单时间  \n",
      "0   2019-04-01 08:00:15  \n",
      "1   2019-04-01 08:45:10  \n",
      "2   2019-04-01 10:03:38  \n",
      "3   2019-04-01 10:58:03  \n",
      "4   2019-04-01 11:35:19  \n",
      "..                  ...  \n",
      "300 2019-04-30 13:29:20  \n",
      "301 2019-04-30 14:05:13  \n",
      "302 2019-04-30 14:45:06  \n",
      "303 2019-04-30 17:46:43  \n",
      "304 2019-04-30 22:07:13  \n",
      "\n",
      "[305 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# 导入pandas模块，并以\"pd\"为该模块的简写\n",
    "import pandas as pd\n",
    "\n",
    "# TODO 使用pd.read_excel()函数和sheet_name参数\n",
    "# 读取路径为 \"/Users/yequ/2019年4月销售订单.xlsx\" 的Excel文件里：\"销售订单数据\" 这个工作表\n",
    "# 并将结果赋值给变量data\n",
    "data = pd.read_excel(\"/Users/xiaojiangyue/programming-study-notes/Python/数据分析/lesson_4_output/yequ/2019年4月销售订单.xlsx\", sheet_name=\"销售订单数据\")\n",
    "\n",
    "# 使用print()输出变量data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aa6313",
   "metadata": {},
   "source": [
    "在pandas模块中，读取Excel文件主要使用pd.read_excel()函数。\n",
    "\n",
    "必选参数：要读取的Excel文件的文件路径\n",
    "\n",
    "常用的可选参数：\n",
    "1. 指定工作表：sheet_name\n",
    "2. 指定行索引：index_col\n",
    "3. 获取指定列：usecols\n",
    "4. 添加columns：header=None和names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84abaa79",
   "metadata": {},
   "source": [
    "# 百题斩题目"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ceea4a",
   "metadata": {},
   "source": [
    "## 随机抽样\n",
    "阿亮是一名银行借贷风险评估师，他想要对一份“借贷用户信息表”做一次抽样调查。\n",
    "\n",
    "这份数据存储在\"/Users/aliang/借贷用户信息表.csv\" 路径下。\n",
    "\n",
    "面对30万条数据的信息表，阿亮想要随机抽取其中1万条数据来做分析。\n",
    "\n",
    "随机抽取后，将抽样数据输出，并保存到\"/Users/aliang/抽取样例信息表.csv\"中。\n",
    "\n",
    "本题中需要用到 随机抽取数据 和 导出数据 这2个知识点，请先点击提示进行学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62772f8",
   "metadata": {},
   "source": [
    "* 随机抽取数据\n",
    "\n",
    "如果需要随机选取数据集中的若干行数据，可以使用pandas模块中的sample()函数。\n",
    "\n",
    "将要抽取的行数作为参数，传入该函数中即可。\n",
    "\n",
    "例如，随机抽取data变量中的100行数据的代码为：\n",
    "`data.sample(100)`\n",
    "\n",
    "\n",
    "* 导出数据\n",
    "\n",
    "处理完数据后，可以使用pandas模块中的to_csv()函数，将处理后的结果导出到指定路径中。\n",
    "\n",
    "该函数的必选参数是文件路径。\n",
    "\n",
    "例如，把data变量保存到路径\"/Users/Desktop/信息表.csv\"下的代码为：\n",
    "`data.to_csv(\"/Users/Desktop/信息表.csv\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c809eba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ListingId   借款金额  借款期限  借款利率      借款成功日期 初始评级   借款类型 是否首标  年龄 性别  ...  \\\n",
      "268118    9439729   3350     9  18.0    2016/3/8    B     其他    否  30  女  ...   \n",
      "271652   15989985   9000    12  18.0   2016/7/22    B     普通    是  36  女  ...   \n",
      "146211   16271163   4232     6  18.0   2016/7/24    B     普通    否  35  女  ...   \n",
      "95884    21748327   3500    12  16.0  2016/10/10    A     其他    否  31  女  ...   \n",
      "12694     2774173   3870     9  11.0   2015/6/14   AA     普通    否  32  男  ...   \n",
      "...           ...    ...   ...   ...         ...  ...    ...  ...  .. ..  ...   \n",
      "135220   10055740  30000    24  18.0   2016/3/24    B     普通    否  27  男  ...   \n",
      "179952   22001475   9931     6  20.0  2016/10/13    C     其他    否  38  男  ...   \n",
      "82383    20103720   6800    12  18.0   2016/9/18    B  APP闪电    否  33  男  ...   \n",
      "81999    13618689   2200     6  16.0   2016/6/17    A  APP闪电    否  46  女  ...   \n",
      "150363    8278273   3933    12  22.0   2016/1/30    D     普通    否  38  男  ...   \n",
      "\n",
      "        待还利息 标当前逾期天数  标当前状态      上次还款日期 上次还款本金 上次还款利息    下次计划还款日期  下次计划还款本金  \\\n",
      "268118  0.00       0    已还清    2016/9/5  46.13   0.61         NaN       NaN   \n",
      "271652  4.27       0  正常还款中   2016/9/19   4.67   0.83  2016/10/22      4.74   \n",
      "146211  1.27       0  正常还款中   2016/9/23   8.15   0.63  2016/10/24      8.27   \n",
      "95884   3.21       0  正常还款中   2016/12/9   4.00   0.63   2017/1/10      4.06   \n",
      "12694   0.00       0    已还清   2016/3/14  57.64   0.49         NaN       NaN   \n",
      "...      ...     ...    ...         ...    ...    ...         ...       ...   \n",
      "135220  5.77       0  正常还款中   2016/9/24   1.88   0.61  2016/10/24      1.90   \n",
      "179952  3.42       0  正常还款中         NaN    NaN    NaN  2016/11/13      9.27   \n",
      "82383   2.92       0  正常还款中  2016/12/18   3.95   0.64   2017/1/18      4.01   \n",
      "81999   0.00       0    已还清  2016/12/17   8.62   0.10         NaN       NaN   \n",
      "150363  0.00       0    已还清   2016/4/20  42.41   0.53         NaN       NaN   \n",
      "\n",
      "        下次计划还款利息  recorddate  \n",
      "268118       NaN  2016/11/30  \n",
      "271652      0.76   2016/9/30  \n",
      "146211      0.50   2016/9/30  \n",
      "95884       0.57  2016/12/31  \n",
      "12694        NaN  2016/12/31  \n",
      "...          ...         ...  \n",
      "135220      0.59   2016/9/30  \n",
      "179952      0.96  2016/10/31  \n",
      "82383       0.57  2016/12/31  \n",
      "81999        NaN  2016/12/31  \n",
      "150363       NaN   2016/9/30  \n",
      "\n",
      "[10000 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "# TODO 导入pandas模块，并以\"pd\"为该模块的简写\n",
    "import pandas as pd\n",
    "\n",
    "# TODO 使用read_csv()函数，获取文件\"/Users/aliang/借贷用户信息表.csv\"，并赋值给变量data\n",
    "data = pd.read_csv(\"/Users/xiaojiangyue/programming-study-notes/Python/数据分析/lesson_4_output/ailang/借贷用户信息表.csv\")\n",
    "\n",
    "# TODO 使用sample()函数，随机抽取样例10000个，并赋值给变量data\n",
    "data = data.sample(10000)\n",
    "\n",
    "# TODO 使用print()输出变量data\n",
    "print(data)\n",
    "\n",
    "# TODO 使用to_csv()函数，将data保存到指定路径\"/Users/aliang/抽取样例信息表.csv\"下\n",
    "data.to_csv(\"/Users/xiaojiangyue/programming-study-notes/Python/数据分析/lesson_4_output/ailang/抽取样例信息表.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac11d3",
   "metadata": {},
   "source": [
    "## 完善会员订单数据\n",
    "某视频网站的会员订单数据如下图所示，可以注意到该数据缺少列名。\n",
    "由于之后的课程里我们会清洗该数据，所以需要给它添加上合适的列名，方便后续处理。\n",
    "\n",
    "这份订单数据存储在\"/Users/yequ/视频会员订单数据源.csv\" 路径下。\n",
    "\n",
    "请在读取这份订单数据时，使用合适的参数，给数据添加以下列名：\"order_id\", \"user_id\", \"price platform\", \"payment_provider\", \"create_time\", \"pay_time\"（我们会在之后的课程中对这些列名的含义进行详细地学习）。\n",
    "\n",
    "完成后，将结果输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd27a097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        order_id  user_id price platform payment_provider       create_time  \\\n",
      "1      105654733    24800            ios         applepay    2020/4/2 16:50   \n",
      "2       47292399    24800        android            wxpay    2020/4/5 16:17   \n",
      "3       97811248     6800        android            wxpay   2019/12/5 16:42   \n",
      "4      106005331     6800            ios            wxpay  2019/11/22 10:06   \n",
      "5      106005331     6800            ios            wxpay    2020/5/24 6:34   \n",
      "...          ...      ...            ...              ...               ...   \n",
      "78045  131148228     2500        android            wxpay   2020/7/31 23:21   \n",
      "78046   32709824     6800        android           alipay   2020/7/31 23:28   \n",
      "78047  129653357    24800            ios         applepay   2020/7/31 23:29   \n",
      "78048  132540663     2500        android            wxpay   2020/7/31 23:30   \n",
      "78049  111527259     2500        android           alipay   2020/7/31 23:34   \n",
      "\n",
      "               pay_time  \n",
      "1        2020/4/2 16:46  \n",
      "2        2020/4/5 16:18  \n",
      "3       2019/12/5 16:42  \n",
      "4      2019/11/22 10:06  \n",
      "5        2020/5/24 6:34  \n",
      "...                 ...  \n",
      "78045   2020/7/31 23:21  \n",
      "78046   2020/7/31 23:28  \n",
      "78047   2020/7/31 23:20  \n",
      "78048   2020/7/31 23:30  \n",
      "78049   2020/7/31 23:30  \n",
      "\n",
      "[78049 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# TODO 导入pandas模块\n",
    "import pandas as pd\n",
    "\n",
    "# TODO 使用pd.read_csv()函数、header参数和names参数\n",
    "# 读取路径为\"/Users/yequ/视频会员订单数据源.csv\" 的CSV文件\n",
    "# 并将数据的列名设置为: \"order_id\", \"user_id\", \"price platform\", \"payment_provider\", \"create_time\", \"pay_time\"\n",
    "# 将结果赋值给变量data\n",
    "data = pd.read_csv(\"/Users/xiaojiangyue/programming-study-notes/Python/数据分析/lesson_4_output/yequ/视频会员订单数据源.csv\", header = None, names = [\"order_id\", \"user_id\", \"price platform\", \"payment_provider\", \"create_time\", \"pay_time\"])\n",
    "\n",
    "# TODO 使用print()输出变量data\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
