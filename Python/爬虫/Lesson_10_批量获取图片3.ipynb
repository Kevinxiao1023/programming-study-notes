{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48fe9f1b",
   "metadata": {},
   "source": [
    "前两天的课程中，我们已经学习了从单个网页中下载图片的方法。\n",
    "\n",
    "今天我们继续学习，在复习前两日所学知识点的基础上，完成下面的内容。\n",
    "1. 通过链接找到每张海报的高清图。\n",
    "2. 学习翻页下载前2页的海报图片。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cf0c42",
   "metadata": {},
   "source": [
    "# 高清图片获取"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfa798b",
   "metadata": {},
   "source": [
    "我们观察下之前获得的图片，可以发现图片的清晰度不够。\n",
    "\n",
    "放大之后比较模糊，这样的图叫做缩略图，那该如何获得高清海报图片呢？\n",
    "\n",
    "为了找到高清图片，我们需要对网页结构进行分析，找到高清图对应的链接。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e79fa9a",
   "metadata": {},
   "source": [
    "接下来，我们回到浏览器打开豆瓣Top250的网页。\n",
    "https://movie.douban.com/top250?start=0&filter=\n",
    "\n",
    "1. 使用选择器，找到图片链接在网页中打开。\n",
    "\n",
    "2. 点击海报图片跳转到新的页面。\n",
    "\n",
    "3. 使用选择器，找到图片链接在新的页面打开。\n",
    "\n",
    "4. 比较两个图片的大小，发现是一样的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b4a688",
   "metadata": {},
   "source": [
    "在上一步操作中，我们找到的两个链接相同，图片尺寸相同。\n",
    "\n",
    "接着，再探索其他的页面，查看是否能够找到清晰度更高的图片。\n",
    "\n",
    "打开进入的第二个页面的链接：\n",
    "\n",
    "1. 点击页面中的海报图片。\n",
    "2. 使用选择器找到第一张图片的链接。\n",
    "3. 复制链接在新页面打开。\n",
    "4. 对比打开的图片，这是清晰度较高的图片。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89880115",
   "metadata": {},
   "source": [
    "总结上页的内容，以一张海报为例，我们需要：\n",
    "\n",
    "1. 首先打开豆瓣的主页面。\n",
    "2. 找到该海报的链接，在页面打开查看。\n",
    "3. 然后点击海报，跳转到海报的主页。\n",
    "4. 在该页面找到海报的链接，打开查看。\n",
    "5. 打开更多海报页面，找到目标海报。\n",
    "6. 获取海报链接下载图片。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f8acdc",
   "metadata": {},
   "source": [
    "首页图片链接和高清图片的链接，两个链接非常相似，只要将图中标黄的部分替换成m，就变成了高清图片链接。\n",
    "\n",
    "图片的后缀名为.webp，这是Google开发的一种图片格式，网站可以使用 WebP 创建尺寸更小、细节更丰富的图片。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec896292",
   "metadata": {},
   "source": [
    "那么将缩略图链接中的字符串进行替换，就能获得高清图的链接。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b57e3",
   "metadata": {},
   "source": [
    "## 替换字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44795e9",
   "metadata": {},
   "source": [
    "replace()函数中要传入两个参数，第一个参数是字符串被替换的内容，第二个参数是要替换成的新内容。     \n",
    "\n",
    "replace()函数可用于把旧的字符串替换成新的字符串。      \n",
    "\n",
    "replace()函数与要替换的字符串用“.”进行连接，点号前面是要替换的字符串变量，点号后面是replace()函数。      \n",
    "\n",
    "使用replace()进行字符串的替换，需要赋值给变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4add131",
   "metadata": {},
   "source": [
    "使用replace()函数我们就巧妙的获得了高清图片的链接。\n",
    "\n",
    "接下来，再次请求图片链接，使用with语句配合open()函数写入图片，就能够获得该页所有海报的高清图片啦。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92772ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用import导入requests模块\n",
    "import requests\n",
    "\n",
    "# 使用from..import从bs4模块导入BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 将电影URL地址，赋值给变量url\n",
    "url = \"https://movie.douban.com/top250\"\n",
    "\n",
    "# 将User-Agent以字典键对形式赋值给headers\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36\"}\n",
    "\n",
    "# 将字典headers传递给headers参数，添加进requests.get()中，赋值给response\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# 将服务器响应内容转换为字符串形式，赋值给html\n",
    "html = response.text\n",
    "\n",
    "# 使用BeautifulSoup()传入变量html和解析器lxml，赋值给soup\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "# 使用find_all()查询soup中class=\"pic\"的节点，赋值给content_all\n",
    "content_all = soup.find_all(class_=\"pic\")\n",
    "\n",
    "# for循环遍历content_all\n",
    "for content in content_all:\n",
    "\n",
    "    # 使用find()查询content中的img标签，并赋值给imgContent\n",
    "    imgContent = content.find(name=\"img\")\n",
    "\n",
    "    # 使用.attrs获取alt对应的属性值，并赋值给imgName\n",
    "    imgName = imgContent.attrs[\"alt\"]\n",
    "    \n",
    "    # 使用.attrs获取src对应的属性值，并赋值给imgUrl\n",
    "    imgUrl = imgContent.attrs[\"src\"]\n",
    "\n",
    "    # 使用replace()函数将链接中的s_ratio_poster替换成m，并赋值给imgUrlHd\n",
    "    imgUrlHd = imgUrl.replace(\"s_ratio_poster\", \"m\")\n",
    "\n",
    "    # TODO 使用requests.get()请求图片链接，赋值给imgResponse\n",
    "    imgResponse = requests.get(imgUrlHd)\n",
    "\n",
    "    # TODO 使用.content属性将响应消息转换成图片数据，赋值给img\n",
    "    img = imgResponse.content\n",
    "\n",
    "    # TODO 使用with语句配合open()函数以图片写入的方式打开文件\n",
    "    # 用格式化将图片名字和.jpg格式组合\n",
    "    # 打开的文件赋值为f\n",
    "    with open(f\"/Users/xiaojiangyue/programming-study-notes/Python/爬虫/lesson_10_output/top_25_高清/{imgName}.jpg\", \"wb\") as f:\n",
    "        # TODO 使用write()将图片写入\n",
    "        f.write(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74201a9",
   "metadata": {},
   "source": [
    "# 批量获取图片"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6997bb",
   "metadata": {},
   "source": [
    "学了单个网页图片获取，那么怎样批量爬取图片呢？\n",
    "\n",
    "观察网页URL的变化规律，每次翻页start=参数增加25。\n",
    "\n",
    "所以，这里我们可以利用for循环生成不同页面的链接。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f188a151",
   "metadata": {},
   "source": [
    "利用for循环生成了每个链接中变化的参数后。\n",
    "\n",
    "接下来，利用字符串拼接，将参数前面内容、参数和参数后面内容，三部分拼接起来即可。\n",
    "\n",
    "但是，for循环生成的参数属于整型，不能直接与字符串进行拼接，需要将整型转为字符串再处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6279c4",
   "metadata": {},
   "source": [
    "## 整型转字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e7b3ae",
   "metadata": {},
   "source": [
    "str()函数可用于将整型转成字符串格式。\n",
    "\n",
    "例如：\n",
    "1. num初始赋值为20。\n",
    "2. 将num传入type()并输出，结果是整型。\n",
    "3. 现在使用str()函数转换后，赋值给string。\n",
    "4. 输出string的类型。\n",
    "\n",
    "可以看到由整型转换成字符串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "160dafd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://movie.douban.com/top250?start=0&filter=\n",
      "https://movie.douban.com/top250?start=25&filter=\n",
      "https://movie.douban.com/top250?start=50&filter=\n",
      "https://movie.douban.com/top250?start=75&filter=\n",
      "https://movie.douban.com/top250?start=100&filter=\n",
      "https://movie.douban.com/top250?start=125&filter=\n",
      "https://movie.douban.com/top250?start=150&filter=\n",
      "https://movie.douban.com/top250?start=175&filter=\n",
      "https://movie.douban.com/top250?start=200&filter=\n",
      "https://movie.douban.com/top250?start=225&filter=\n",
      "https://movie.douban.com/top250?start=250&filter=\n"
     ]
    }
   ],
   "source": [
    "# 使用for循环遍历range()函数生成的0-10的数字\n",
    "for i in range(0, 11):\n",
    "\n",
    "    # 取遍历中的每个数和25相乘计算每页的数值，并赋值给page\n",
    "    page = i * 25\n",
    "\n",
    "    # TODO 用\"https://movie.douban.com/top250?start=\"和page转换成的字符串格式相连，接着连上\"&filter=\"，并赋值给url\n",
    "    url = \"https://movie.douban.com/top250?start=\" + str(page) + \"&filter=\"\n",
    "\n",
    "    # TODO 使用print输出url\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d79b918",
   "metadata": {},
   "source": [
    "通过对for循环和整数转字符串知识点的组合，我们就生成了多个URL。\n",
    "\n",
    "接下来，将之前单个页面的URL替换成可生成多个URL的代码。      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b6fb8",
   "metadata": {},
   "source": [
    "通过以上的学习，我们就完成了批量下载高清图片的方法。\n",
    "\n",
    "回顾今日所学知识点：\n",
    "\n",
    "1. 分析网页结构，找到高清图链接。\n",
    "2. 使用for循环完成网页翻页过程。\n",
    "3. 最后实现了批量下载高清海报图片的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d02d12b",
   "metadata": {},
   "source": [
    "# 百词斩题目"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d1dac5",
   "metadata": {},
   "source": [
    "## 正确网址         \n",
    "\n",
    "小倩想爬取某网页的内容，但是网站的网址乱码了。 经过观察，小倩发现，网址中的“/”被替换成了中文的“！”和“。”两种符号。\n",
    "需要进行处理的网址是：\n",
    "`https:！！www.pexels.com。zh-cn。photo！4996652` 。\n",
    "\n",
    "题目要求：\n",
    "1. 将网址进行处理，获得正确的网址；\n",
    "2.将正确的网址和headers传入requests()函数，请求响应；\n",
    "3.输出获取到的响应中前200个字符的内容。\n",
    "\n",
    "\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a7c689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 8]>    <html class=\"no-\n"
     ]
    }
   ],
   "source": [
    "# TODO 使用import导入requests模块\n",
    "import requests\n",
    "\n",
    "# TODO 将错误网址赋值给字符串sentence\n",
    "sentence = \"https:！！www.pexels.com。zh-cn。photo！4996652。\"\n",
    "\n",
    "# TODO 使用replace()函数对字符串中的“。”进行替换，并将结果赋值给newSentence\n",
    "newSentence = sentence.replace(\"。\", \"/\")\n",
    "\n",
    "# TODO 使用replace()函数对字符串中的“！”进行替换，并将结果赋值给url\n",
    "url = newSentence.replace(\"！\", \"/\")\n",
    "\n",
    "# 将User-Agent以字典键对形式赋值给headers\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36\"}\n",
    "\n",
    "# TODO 将字典headers传递给headers参数\n",
    "# 将 url 和 headers参数，添加进requests.get()中，赋值给response\n",
    "response = requests.get(url, headers = headers)\n",
    "\n",
    "# TODO 将服务器响应内容转换为字符串形式，赋值给html\n",
    "html = response.text\n",
    "\n",
    "# TODO 输出获取到的前200个字符\n",
    "print(html[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e45be70",
   "metadata": {},
   "source": [
    "## 豆瓣TOP100          \n",
    "\n",
    "静静想要给用户推荐豆瓣TOP100的电影，需要梳理出这 100部电影的名单(包含中外语名称)，如果去网页中一个一个的统计可就太麻烦了，这可怎么办呢？\n",
    "\n",
    "通过这几天的学习静静想到了好办法，静静发现虽然100部电影有4个网页链接，但是链接的大部分内容是相同的，每翻一页start后面的增加25。\n",
    "```\n",
    "第一页：https://movie.douban.com/top250?start=0&filter=\n",
    "第二页：https://movie.douban.com/top250?start=25&filter=\n",
    "第三页：https://movie.douban.com/top250?start=50&filter=\n",
    "第四页：https://movie.douban.com/top250?start=75&filter=\n",
    "```\n",
    "整理下思路：\n",
    "1. 获取User-Agent，设置请求头；\n",
    "2. 使用for循环和整数型转成字符串数据类型的知识，获取4页的URL；\n",
    "例如：`url = \"https://movie.douban.com/top250?start=\" + str(page) + \"&filter=\"`\n",
    "3. 将url和headers参数，添加进requests.get()中，获取网页HTML代码；\n",
    "4. 创建一个BeautifulSoup对象，使用find_all()函数获取节点；\n",
    "5. 调用.string属性，获取每个节点中标签内的内容。\n",
    "\n",
    "`User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37f561c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "肖申克的救赎\n",
      " / The Shawshank Redemption\n",
      "霸王别姬\n",
      "阿甘正传\n",
      " / Forrest Gump\n",
      "泰坦尼克号\n",
      " / Titanic\n",
      "这个杀手不太冷\n",
      " / Léon\n",
      "美丽人生\n",
      " / La vita è bella\n",
      "千与千寻\n",
      " / 千と千尋の神隠し\n",
      "辛德勒的名单\n",
      " / Schindler's List\n",
      "盗梦空间\n",
      " / Inception\n",
      "忠犬八公的故事\n",
      " / Hachi: A Dog's Tale\n",
      "星际穿越\n",
      " / Interstellar\n",
      "楚门的世界\n",
      " / The Truman Show\n",
      "海上钢琴师\n",
      " / La leggenda del pianista sull'oceano\n",
      "三傻大闹宝莱坞\n",
      " / 3 Idiots\n",
      "机器人总动员\n",
      " / WALL·E\n",
      "放牛班的春天\n",
      " / Les choristes\n",
      "无间道\n",
      " / 無間道\n",
      "疯狂动物城\n",
      " / Zootopia\n",
      "大话西游之大圣娶亲\n",
      " / 西遊記大結局之仙履奇緣\n",
      "熔炉\n",
      " / 도가니\n",
      "教父\n",
      " / The Godfather\n",
      "当幸福来敲门\n",
      " / The Pursuit of Happyness\n",
      "控方证人\n",
      " / Witness for the Prosecution\n",
      "龙猫\n",
      " / となりのトトロ\n",
      "怦然心动\n",
      " / Flipped\n",
      "触不可及\n",
      " / Intouchables\n",
      "末代皇帝\n",
      " / The Last Emperor\n",
      "蝙蝠侠：黑暗骑士\n",
      " / The Dark Knight\n",
      "寻梦环游记\n",
      " / Coco\n",
      "活着\n",
      "哈利·波特与魔法石\n",
      " / Harry Potter and the Sorcerer's Stone\n",
      "指环王3：王者无敌\n",
      " / The Lord of the Rings: The Return of the King\n",
      "乱世佳人\n",
      " / Gone with the Wind\n",
      "素媛\n",
      " / 소원\n",
      "飞屋环游记\n",
      " / Up\n",
      "摔跤吧！爸爸\n",
      " / Dangal\n",
      "何以为家\n",
      " / كفرناحوم\n",
      "我不是药神\n",
      "十二怒汉\n",
      " / 12 Angry Men\n",
      "哈尔的移动城堡\n",
      " / ハウルの動く城\n",
      "少年派的奇幻漂流\n",
      " / Life of Pi\n",
      "鬼子来了\n",
      "大话西游之月光宝盒\n",
      " / 西遊記第壹佰零壹回之月光寶盒\n",
      "天空之城\n",
      " / 天空の城ラピュタ\n",
      "猫鼠游戏\n",
      " / Catch Me If You Can\n",
      "天堂电影院\n",
      " / Nuovo Cinema Paradiso\n",
      "闻香识女人\n",
      " / Scent of a Woman\n",
      "指环王2：双塔奇兵\n",
      " / The Lord of the Rings: The Two Towers\n",
      "罗马假日\n",
      " / Roman Holiday\n",
      "钢琴家\n",
      " / The Pianist\n",
      "让子弹飞\n",
      "指环王1：护戒使者\n",
      " / The Lord of the Rings: The Fellowship of the Ring\n",
      "辩护人\n",
      " / 변호인\n",
      "大闹天宫\n",
      "黑客帝国\n",
      " / The Matrix\n",
      "教父2\n",
      " / The Godfather: Part Ⅱ\n",
      "海蒂和爷爷\n",
      " / Heidi\n",
      "死亡诗社\n",
      " / Dead Poets Society\n",
      "狮子王\n",
      " / The Lion King\n",
      "绿皮书\n",
      " / Green Book\n",
      "搏击俱乐部\n",
      " / Fight Club\n",
      "饮食男女\n",
      " / 飲食男女\n",
      "美丽心灵\n",
      " / A Beautiful Mind\n",
      "窃听风暴\n",
      " / Das Leben der Anderen\n",
      "本杰明·巴顿奇事\n",
      " / The Curious Case of Benjamin Button\n",
      "情书\n",
      " / Love Letter\n",
      "两杆大烟枪\n",
      " / Lock, Stock and Two Smoking Barrels\n",
      "穿条纹睡衣的男孩\n",
      " / The Boy in the Striped Pajamas\n",
      "西西里的美丽传说\n",
      " / Malèna\n",
      "看不见的客人\n",
      " / Contratiempo\n",
      "飞越疯人院\n",
      " / One Flew Over the Cuckoo's Nest\n",
      "拯救大兵瑞恩\n",
      " / Saving Private Ryan\n",
      "音乐之声\n",
      " / The Sound of Music\n",
      "小鞋子\n",
      " / بچه های آسمان\n",
      "阿凡达\n",
      " / Avatar\n",
      "海豚湾\n",
      " / The Cove\n",
      "沉默的羔羊\n",
      " / The Silence of the Lambs\n",
      "致命魔术\n",
      " / The Prestige\n",
      "哈利·波特与死亡圣器(下)\n",
      " / Harry Potter and the Deathly Hallows: Part 2\n",
      "美国往事\n",
      " / Once Upon a Time in America\n",
      "禁闭岛\n",
      " / Shutter Island\n",
      "蝴蝶效应\n",
      " / The Butterfly Effect\n",
      "布达佩斯大饭店\n",
      " / The Grand Budapest Hotel\n",
      "心灵捕手\n",
      " / Good Will Hunting\n",
      "低俗小说\n",
      " / Pulp Fiction\n",
      "春光乍泄\n",
      " / 春光乍洩\n",
      "摩登时代\n",
      " / Modern Times\n",
      "七宗罪\n",
      " / Se7en\n",
      "喜剧之王\n",
      " / 喜劇之王\n",
      "致命ID\n",
      " / Identity\n",
      "杀人回忆\n",
      " / 살인의 추억\n",
      "被嫌弃的松子的一生\n",
      " / 嫌われ松子の一生\n",
      "加勒比海盗\n",
      " / Pirates of the Caribbean: The Curse of the Black Pearl\n",
      "红辣椒\n",
      " / パプリカ\n",
      "狩猎\n",
      " / Jagten\n",
      "功夫\n",
      "请以你的名字呼唤我\n",
      " / Call Me by Your Name\n",
      "剪刀手爱德华\n",
      " / Edward Scissorhands\n",
      "超脱\n",
      " / Detachment\n",
      "哈利·波特与阿兹卡班的囚徒\n",
      " / Harry Potter and the Prisoner of Azkaban\n"
     ]
    }
   ],
   "source": [
    "# 使用import导入requests模块\n",
    "import requests\n",
    "\n",
    "# 从bs4中导入BeautifulSoup模块\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 将User-Agent以字典键对形式赋值给headers\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36\"}\n",
    "\n",
    "# TODO 使用for循环遍历range()函数生成的0-3的数字\n",
    "for i in range(0, 4):\n",
    "\n",
    "    # TODO 取遍历中的每个数和25相乘计算每页的数值，并赋值给page\n",
    "    page = i * 25\n",
    "\n",
    "    # TODO 用\"https://movie.douban.com/top250?start=\"和page转换成的字符串格式相连，接着在连上\"&filter=\"，并赋值给url\n",
    "    url = \"https://movie.douban.com/top250?start=\" + str(page) + \"&filter=\"\n",
    "\n",
    "    # TODO 将字典headers传递给headers参数\n",
    "    # 将 url 和 headers参数，添加进requests.get()中，赋值给response\n",
    "    response = requests.get(url, headers = headers)\n",
    "\n",
    "    # TODO 将服务器响应内容转换为字符串形式，赋值给html\n",
    "    html = response.text\n",
    "\n",
    "    # TODO 用BeautifulSoup()传入变量html和解析器lxml，赋值给soup\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "    # TODO 使用find_all()查询soup中class=title的节点，赋值给content_all\n",
    "    content_all = soup.find_all(class_ = \"title\")\n",
    "\n",
    "    # TODO for循环遍历content_all\n",
    "    for content in content_all:\n",
    "\n",
    "        # TODO 获取每个节点中标签内的内容，赋值给contentString\n",
    "        contentString = content.string\n",
    "    \n",
    "        # TODO 使用print输出contentString\n",
    "        print(contentString)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b127792",
   "metadata": {},
   "source": [
    "## 电脑壁纸             \n",
    "\n",
    "小红是一个故宫迷，非常喜欢收集故宫的周边产品。她计划利用爬虫知识点，从网站批量下载前三页的壁纸：\n",
    "https://www.dpm.org.cn/lights/royal.html\n",
    "\n",
    "【题目要求】\n",
    "1. 下载的图片以数字+.jpg的方式保存，数字从1开始计数；\n",
    "2. 下载的图片保存到路径/Users/pic。\n",
    "\n",
    "注意：在本题中，我们会发现，点击第二页后，浏览器的网址不变，那我们该如何获取第二页的图片的url网址呢？\n",
    "\n",
    "提示：当我们无法直接通过浏览器找到url的变化时，我们可以将选择器定位到页码按钮，查看具体的url地址。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80a14d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36 Edg/97.0.1072.62\"}\n",
    "count = 1\n",
    "\n",
    "for i in range(1, 4):\n",
    "    url = \"https://www.dpm.org.cn/lights/royal/p/\" + str(i) + \".html\"\n",
    "    response = requests.get(url, headers = headers)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    content_all = soup.find_all(class_ = \"pic\")\n",
    "    \n",
    "    for content in content_all:\n",
    "        imgContent = content.find(name = \"img\")\n",
    "        imgUrl = imgContent.attrs[\"src\"]\n",
    "        imgResponse = requests.get(imgUrl)\n",
    "        img = imgResponse.content\n",
    "        \n",
    "        with open(f\"/Users/xiaojiangyue/programming-study-notes/Python/爬虫/lesson_10_output/电脑壁纸/{count}.jpg\", \"wb\") as f:\n",
    "            f.write(img)\n",
    "            \n",
    "        count = count + 1\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
